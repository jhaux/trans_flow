{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, conditioner, forward_is_backward=False):\n",
    "        super().__init__()\n",
    "        self.C = conditioner\n",
    "        self.is_forward = not forward_is_backward\n",
    "        \n",
    "    def forward(self, value, is_forward=True):\n",
    "        translation, log_scale = self.C(value)\n",
    "        \n",
    "        self.log_scale = log_scale\n",
    "        self.translation = translation\n",
    "        self.scale = scale = log_scale.exp()\n",
    "        \n",
    "        if is_forward:\n",
    "            return scale * value + translation\n",
    "        else:\n",
    "            return (value - translation) / scale\n",
    "    \n",
    "    def inverse(self, value):\n",
    "        return self(value, is_forward=False)\n",
    "    \n",
    "    def inv(self, value):\n",
    "        return self.inverse(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCC(nn.Module):\n",
    "    def __init__(self, nc, n_hidden=128, n_layers=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.nc = nc\n",
    "        \n",
    "        layers = []\n",
    "        layers += [nn.Linear(nc, n_hidden), nn.ReLU()]\n",
    "        \n",
    "        for i in range(1, n_layers-1):\n",
    "            layers += [nn.Linear(n_hidden, n_hidden), nn.ReLU()]\n",
    "            \n",
    "        layers += [nn.Linear(n_hidden, 2*nc)]\n",
    "        \n",
    "        self.fn = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, value):\n",
    "        pars = self.fn(value)\n",
    "        translation, scale = pars[:, :self.nc], pars[:, self.nc:]\n",
    "        \n",
    "        return translation, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCC(\n",
      "  (fn): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0654, -0.0805]], grad_fn=<SliceBackward>),\n",
       " tensor([[ 0.1140, -0.0924]], grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcc = FCC(2)\n",
    "print(fcc)\n",
    "\n",
    "fcc(torch.from_numpy(np.ones([1, 2])).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (C): FCC(\n",
      "    (fn): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "tensor([[1.0554, 0.8312]], grad_fn=<AddBackward0>)\n",
      "tensor([[0.9506, 1.1851]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "T = Transformer(fcc)\n",
    "print(T)\n",
    "value = torch.from_numpy(np.ones([1, 2])).float()\n",
    "print(T(value))\n",
    "print(T.inv(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edflow.data.dataset_mixin import DatasetMixin\n",
    "from edflow.util import edprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoonDataset(DatasetMixin):\n",
    "    def __init__(self, n_samples=1500, noise=0.05):\n",
    "        self.X, self.y = datasets.make_moons(n_samples=n_samples, noise=noise)\n",
    "        \n",
    "        self.append_labels = True\n",
    "        \n",
    "    @property\n",
    "    def labels(self):\n",
    "        if not hasattr(self, '_labels'):\n",
    "            self._labels = {}\n",
    "            self._labels['X'] = self.X\n",
    "            self._labels['y'] = self.y\n",
    "        return self._labels\n",
    "    \n",
    "    def get_example(self, idx):\n",
    "        return {}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalDataset(DatasetMixin):\n",
    "    def __init__(self, nc, n_samples=1500):\n",
    "        self.X = np.random.normal(size=[n_samples, nc])\n",
    "        self.X[:, 0] = self.X[:, 0] / self.X[:, 0].max()\n",
    "        self.X[:, 1] = self.X[:, 1] / self.X[:, 1].max()\n",
    "        self.append_labels = True\n",
    "        \n",
    "    @property\n",
    "    def labels(self):\n",
    "        if not hasattr(self, '_labels'):\n",
    "            self._labels = {}\n",
    "            self._labels['X'] = self.X\n",
    "        return self._labels\n",
    "    \n",
    "    def get_example(self, idx):\n",
    "        return {}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.3, 1.3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Moon = MoonDataset()\n",
    "N = NormalDataset(2)\n",
    "\n",
    "X = Moon.labels['X']\n",
    "y = Moon.labels['y']\n",
    "X_norm = N.labels['X']\n",
    "\n",
    "f, [ax1, ax2] = plt.subplots(1, 2)\n",
    "\n",
    "xlim = [-1.3, 2.3]\n",
    "ylim = [-1.3, 1.3]\n",
    "\n",
    "ax1.set_aspect(1)\n",
    "ax2.set_aspect(1)\n",
    "\n",
    "ax1.scatter(X_norm[:, 0], X_norm[:, 1])\n",
    "ax2.scatter(X[:, 0], X[:, 1], c=y)\n",
    "\n",
    "ax1.set_xlim(*xlim)\n",
    "ax2.set_xlim(*xlim)\n",
    "ax1.set_ylim(*ylim)\n",
    "ax2.set_ylim(*ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|        Name |      Type |   Content |\n",
       "|-------------|-----------|-----------|\n",
       "|      index_ |       int |         0 |\n",
       "|   labels_/X |   ndarray |      (2,) |\n",
       "|   labels_/y |     int64 |         0 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edprint(Moon[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, n_transformers=4):\n",
    "        super().__init__()\n",
    "        self.transformers = nn.ModuleList()\n",
    "        for i in range(n_transformers):\n",
    "            C = FCC(2)\n",
    "            T = Transformer(C)\n",
    "            self.transformers += [T]\n",
    "\n",
    "    def forward(self, value, is_forward=True):\n",
    "        self.conditions = {'translation': [], 'scale': []}\n",
    "        if is_forward:\n",
    "            for T in self.transformers:\n",
    "                value = T(value, is_forward=True)\n",
    "                self.conditions['translation'] += [T.translation]\n",
    "                self.conditions['scale'] += [T.scale]\n",
    "                self.conditions['log_scale'] += [T.log_scale]\n",
    "        else:\n",
    "            for T in self.transformers[::-1]:\n",
    "                value = T(value, is_forward=False)\n",
    "                self.conditions['translation'] += [T.translation]\n",
    "                self.conditions['log_scale'] += [T.log_scale]\n",
    "            \n",
    "        return value\n",
    "    \n",
    "    def inverse(self, value):\n",
    "        return self(value, is_forward=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (transformers): ModuleList(\n",
      "    (0): Transformer(\n",
      "      (C): FCC(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=2, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "TM1 = TransformerModel(1)\n",
    "print(TM1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edflow.iterators.template_iterator import TemplateIterator\n",
    "from edflow.custom_logging import init_project\n",
    "from edflow.iterators.batches import make_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iterator(TemplateIterator):\n",
    "    def __init__(self, config, root, model, dataset, **kwargs):\n",
    "        self.model = model\n",
    "        \n",
    "        self.optim = torch.optim.SGD(self.model.parameters(), lr=1, momentum=0.9)\n",
    "        \n",
    "        super().__init__(config, root, model, dataset, **kwargs)\n",
    "        \n",
    "    def step_op(self, _, labels_, **kwargs):\n",
    "        X = torch.from_numpy(labels_['X']).float()\n",
    "        \n",
    "        Y = self.model(X)\n",
    "        log_scales = self.model.conditions['log_scale']\n",
    "        \n",
    "        log_det_loss = 0\n",
    "        for scale in scales:\n",
    "            log_det_loss += -log_scales.sum(-1)\n",
    "        log_det_loss = torch.mean(log_det_loss)\n",
    "        \n",
    "        kl_loss = torch.mean(Y ** 2)\n",
    "        \n",
    "        loss = kl_loss + log_det_loss\n",
    "        \n",
    "        def train_op():\n",
    "            self.optim.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            self.optim.step()\n",
    "        \n",
    "        def eval_op():\n",
    "            pass\n",
    "        \n",
    "        def log_op():\n",
    "            return {'loss': loss}\n",
    "        \n",
    "        return {'train_op': train_op, 'eval_op': eval_op, 'log_op': log_op}\n",
    "    \n",
    "    def save(self, path):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = init_project('logs', code_root=None, postfix='tflow')\n",
    "\n",
    "Trainer = Iterator({'test_mode': False}, P.root, TM1, Moon, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3e7fdc0b014b239aad78712789b5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', layout=Layout(flex='2'), max=5.0, style=ProgressS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721f8c86cddc49dea6105d109dd104f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', layout=Layout(flex='2'), max=24.0, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "[INFO] [LambdaCheckpointHook]: Saved model to logs/2020-01-05T14-27-29_tflow/train/checkpoints/model-2400.ckpt\n",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "[INFO] [LambdaCheckpointHook]: Saved model to logs/2020-01-05T14-27-29_tflow/train/checkpoints/model-240.ckpt\n",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "[INFO] [LambdaCheckpointHook]: Saved model to logs/2020-01-05T14-27-29_tflow/train/checkpoints/model-120.ckpt\n",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "[INFO] [LambdaCheckpointHook]: Saved model to logs/2020-01-05T14-27-29_tflow/train/checkpoints/model-120.ckpt\n",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "[INFO] [LambdaCheckpointHook]: Saved model to logs/2020-01-05T14-27-29_tflow/train/checkpoints/model-0.ckpt\n",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "[INFO] [LambdaCheckpointHook]: Saved model to logs/2020-01-05T14-27-29_tflow/train/checkpoints/model-0.ckpt\n",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "[INFO] [LambdaCheckpointHook]: Saved model to logs/2020-01-05T14-27-29_tflow/train/checkpoints/model-0.ckpt\n",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "[INFO] [LambdaCheckpointHook]: Saved model to logs/2020-01-05T14-27-29_tflow/train/checkpoints/model-0.ckpt\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'log_scale'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-2a765ead89cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMoon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/edflow/edflow/edflow/iterators/model_iterator.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self, batch_iterator, batch_iterator_validation)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_iterator_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/edflow/edflow/edflow/iterators/model_iterator.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self, batch_iterator, batch_iterator_validation)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_iterator_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/edflow/edflow/edflow/iterators/model_iterator.py\u001b[0m in \u001b[0;36m_iterate\u001b[0;34m(self, batch_iterator, batch_iterator_validation)\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0mfeeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_feeds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/edflow/edflow/edflow/iterators/template_iterator.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/edflow/edflow/edflow/iterators/model_iterator.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/edflow/edflow/edflow/util.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(dict_or_list, fn, inplace, pass_key, prev_key, splitval, walk_np_arrays)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict_or_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpass_key\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/edflow/edflow/edflow/util.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwalk_np_arrays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwalk_np_arrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/edflow/edflow/edflow/iterators/model_iterator.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(fetch_fn)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-72-5b2a9c20c56d>\u001b[0m in \u001b[0;36mstep_op\u001b[0;34m(self, _, labels_, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mlog_scales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconditions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log_scale'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlog_det_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'log_scale'"
     ]
    }
   ],
   "source": [
    "Trainer.iterate(make_batches(Moon, batch_size=64, shuffle=True))\n",
    "\n",
    "del P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
