{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, conditioner, forward_is_backward=False):\n",
    "        super().__init__()\n",
    "        self.C = conditioner\n",
    "        self.is_forward = not forward_is_backward\n",
    "        \n",
    "    def forward(self, value, is_forward=True):\n",
    "        translation, log_scale = self.C(value)\n",
    "        \n",
    "        self.log_scale = log_scale\n",
    "        self.translation = translation\n",
    "        self.scale = scale = log_scale.exp()\n",
    "        \n",
    "        if is_forward:\n",
    "            return scale * value + translation\n",
    "        else:\n",
    "            return (value - translation) / scale\n",
    "    \n",
    "    def inverse(self, value):\n",
    "        return self(value, is_forward=False)\n",
    "    \n",
    "    def inv(self, value):\n",
    "        return self.inverse(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCC(nn.Module):\n",
    "    def __init__(self, nc, n_hidden=128, n_layers=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.nc = nc\n",
    "        \n",
    "        layers = []\n",
    "        layers += [nn.Linear(nc, n_hidden), nn.ReLU()]\n",
    "        \n",
    "        for i in range(1, n_layers-1):\n",
    "            layers += [nn.Linear(n_hidden, n_hidden), nn.ReLU()]\n",
    "            \n",
    "        layers += [nn.Linear(n_hidden, 2*nc)]\n",
    "        \n",
    "        self.fn = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, value):\n",
    "        pars = self.fn(value)\n",
    "        translation, scale = pars[:, :self.nc], pars[:, self.nc:]\n",
    "        \n",
    "        return translation, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCC(\n",
      "  (fn): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0466, 0.1078]], grad_fn=<SliceBackward>),\n",
       " tensor([[ 0.1103, -0.0142]], grad_fn=<SliceBackward>))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcc = FCC(2)\n",
    "print(fcc)\n",
    "\n",
    "fcc(torch.from_numpy(np.ones([1, 2])).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (C): FCC(\n",
      "    (fn): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "tensor([[1.1632, 1.0937]], grad_fn=<AddBackward0>)\n",
      "tensor([[0.8539, 0.9049]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "T = Transformer(fcc)\n",
    "print(T)\n",
    "value = torch.from_numpy(np.ones([1, 2])).float()\n",
    "print(T(value))\n",
    "print(T.inv(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jhaux/Projects/edflow/edflow/edflow/custom_logging.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from edflow.data.dataset_mixin import DatasetMixin\n",
    "from edflow.util import edprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoonDataset(DatasetMixin):\n",
    "    def __init__(self, n_samples=1500, noise=0.05):\n",
    "        self.X, self.y = datasets.make_moons(n_samples=n_samples, noise=noise)\n",
    "        \n",
    "        self.append_labels = True\n",
    "        \n",
    "    @property\n",
    "    def labels(self):\n",
    "        if not hasattr(self, '_labels'):\n",
    "            self._labels = {}\n",
    "            self._labels['X'] = self.X\n",
    "            self._labels['y'] = self.y\n",
    "        return self._labels\n",
    "    \n",
    "    def get_example(self, idx):\n",
    "        return {}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalDataset(DatasetMixin):\n",
    "    def __init__(self, nc, n_samples=1500):\n",
    "        self.X = np.random.normal(size=[n_samples, nc])\n",
    "        self.X[:, 0] = self.X[:, 0] / self.X[:, 0].max()\n",
    "        self.X[:, 1] = self.X[:, 1] / self.X[:, 1].max()\n",
    "        self.append_labels = True\n",
    "        \n",
    "    @property\n",
    "    def labels(self):\n",
    "        if not hasattr(self, '_labels'):\n",
    "            self._labels = {}\n",
    "            self._labels['X'] = self.X\n",
    "        return self._labels\n",
    "    \n",
    "    def get_example(self, idx):\n",
    "        return {}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.3, 1.3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Moon = MoonDataset()\n",
    "N = NormalDataset(2)\n",
    "\n",
    "X = Moon.labels['X']\n",
    "y = Moon.labels['y']\n",
    "X_norm = N.labels['X']\n",
    "\n",
    "f, [ax1, ax2] = plt.subplots(1, 2)\n",
    "\n",
    "xlim = [-1.3, 2.3]\n",
    "ylim = [-1.3, 1.3]\n",
    "\n",
    "ax1.set_aspect(1)\n",
    "ax2.set_aspect(1)\n",
    "\n",
    "ax1.scatter(X_norm[:, 0], X_norm[:, 1])\n",
    "ax2.scatter(X[:, 0], X[:, 1], c=y)\n",
    "\n",
    "ax1.set_xlim(*xlim)\n",
    "ax2.set_xlim(*xlim)\n",
    "ax1.set_ylim(*ylim)\n",
    "ax2.set_ylim(*ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|        Name |      Type |   Content |\n",
       "|-------------|-----------|-----------|\n",
       "|      index_ |       int |         0 |\n",
       "|   labels_/X |   ndarray |      (2,) |\n",
       "|   labels_/y |     int64 |         1 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edprint(Moon[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, n_transformers=4):\n",
    "        super().__init__()\n",
    "        self.transformers = nn.ModuleList()\n",
    "        for i in range(n_transformers):\n",
    "            C = FCC(2)\n",
    "            T = Transformer(C)\n",
    "            self.transformers += [T]\n",
    "\n",
    "    def forward(self, value, is_forward=True):\n",
    "        self.conditions = {'translation': [], 'scale': [], 'log_scale': []}\n",
    "        if is_forward:\n",
    "            for T in self.transformers:\n",
    "                value = T(value, is_forward=True)\n",
    "                self.conditions['translation'] += [T.translation]\n",
    "                self.conditions['scale'] += [T.scale]\n",
    "                self.conditions['log_scale'] += [T.log_scale]\n",
    "        else:\n",
    "            for T in self.transformers[::-1]:\n",
    "                value = T(value, is_forward=False)\n",
    "                self.conditions['translation'] += [T.translation]\n",
    "                self.conditions['log_scale'] += [T.log_scale]\n",
    "            \n",
    "        return value\n",
    "    \n",
    "    def inverse(self, value):\n",
    "        return self(value, is_forward=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (transformers): ModuleList(\n",
      "    (0): Transformer(\n",
      "      (C): FCC(\n",
      "        (fn): Sequential(\n",
      "          (0): Linear(in_features=2, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (3): ReLU()\n",
      "          (4): Linear(in_features=128, out_features=4, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "TM1 = TransformerModel(1)\n",
    "print(TM1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edflow.iterators.template_iterator import TemplateIterator\n",
    "from edflow.custom_logging import init_project\n",
    "from edflow.iterators.batches import make_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iterator(TemplateIterator):\n",
    "    def __init__(self, config, root, model, dataset, **kwargs):\n",
    "        self.model = model\n",
    "        \n",
    "        self.optim = torch.optim.SGD(self.model.parameters(), lr=1, momentum=0.9)\n",
    "        \n",
    "        super().__init__(config, root, model, dataset, **kwargs)\n",
    "        \n",
    "    def step_op(self, _, labels_, **kwargs):\n",
    "        X = torch.from_numpy(labels_['X']).float()\n",
    "        \n",
    "        Y = self.model(X)\n",
    "        log_scales = self.model.conditions['log_scale']\n",
    "        \n",
    "        log_det_loss = -log_scales[0].sum(-1)\n",
    "        for log_scale in log_scales[1:]:\n",
    "            log_det_loss += -log_scale.sum(-1)\n",
    "        log_det_loss = torch.mean(log_det_loss)\n",
    "        \n",
    "        kl_loss = torch.mean(Y ** 2)\n",
    "        \n",
    "        loss = kl_loss + log_det_loss\n",
    "        \n",
    "        def train_op():\n",
    "            self.optim.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            self.optim.step()\n",
    "        \n",
    "        def eval_op():\n",
    "            pass\n",
    "        \n",
    "        def log_op():\n",
    "            return {'scalars': {'loss': loss, 'kl': kl_loss, 'det': log_det_loss}}\n",
    "        \n",
    "        return {'train_op': train_op, 'eval_op': eval_op, 'log_op': log_op}\n",
    "    \n",
    "    def save(self, path):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = init_project('logs', code_root=None, postfix='tflow')\n",
    "\n",
    "Trainer = Iterator({'test_mode': False}, P.root, TM1, Moon, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc2d8dc2eb14ad9a52b7a0fe0ed74d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', layout=Layout(flex='2'), max=5.0, style=ProgressS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00e502638cf4880a274276bac9381ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', layout=Layout(flex='2'), max=24.0, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [train]: global_step: 0\n",
      "[INFO] [train]: det: nan\n",
      "[INFO] [train]: kl: nan\n",
      "[INFO] [train]: loss: nan\n",
      "[INFO] [train]: logging root: logs/2020-01-05T15-21-19_tflow/train\n",
      "[INFO] [train]: global_step: 0\n",
      "[INFO] [train]: det: nan\n",
      "[INFO] [train]: kl: nan\n",
      "[INFO] [train]: loss: nan\n",
      "[INFO] [train]: logging root: logs/2020-01-05T15-21-19_tflow/train\n",
      "[INFO] [Iterator]: Done with epoch\n",
      "\n",
      "[INFO] [LambdaCheckpointHook]: Saved model to logs/2020-01-05T15-21-19_tflow/train/checkpoints/model-120.ckpt\n",
      "[INFO] [LambdaCheckpointHook]: Saved model to logs/2020-01-05T15-21-19_tflow/train/checkpoints/model-24.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d04bc8fcad94a588d26ce6a1763b99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', layout=Layout(flex='2'), max=24.0, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "[INFO] [Iterator]: Done with epoch\n",
      "\n",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "[INFO] [LambdaCheckpointHook]: Saved model to logs/2020-01-05T15-21-19_tflow/train/checkpoints/model-120.ckpt\n",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "[INFO] [LambdaCheckpointHook]: Saved model to logs/2020-01-05T15-21-19_tflow/train/checkpoints/model-48.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4085e581c3841498f9f5919034d2c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', layout=Layout(flex='2'), max=24.0, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "[INFO] [Iterator]: Done with epoch\n",
      "\n",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "[INFO] [LambdaCheckpointHook]: Saved model to logs/2020-01-05T15-21-19_tflow/train/checkpoints/model-120.ckpt\n",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "[INFO] [LambdaCheckpointHook]: Saved model to logs/2020-01-05T15-21-19_tflow/train/checkpoints/model-72.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c8b9112fa8413a8a4ec0b0b972499c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', layout=Layout(flex='2'), max=24.0, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "[INFO] [Iterator]: Done with epoch\n",
      "\n",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "[INFO] [LambdaCheckpointHook]: Saved model to logs/2020-01-05T15-21-19_tflow/train/checkpoints/model-120.ckpt\n",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "[INFO] [LambdaCheckpointHook]: Saved model to logs/2020-01-05T15-21-19_tflow/train/checkpoints/model-96.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b2a91fcee64e189ac380c9c80cdb6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Batch', layout=Layout(flex='2'), max=24.0, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [train]: global_step: 100\n",
      "[INFO] [train]: det: nan\n",
      "[INFO] [train]: kl: nan\n",
      "[INFO] [train]: loss: nan\n",
      "[INFO] [train]: logging root: logs/2020-01-05T15-21-19_tflow/train\n",
      "[INFO] [train]: global_step: 100\n",
      "[INFO] [train]: det: nan\n",
      "[INFO] [train]: kl: nan\n",
      "[INFO] [train]: loss: nan\n",
      "[INFO] [train]: logging root: logs/2020-01-05T15-21-19_tflow/train\n",
      "[INFO] [Iterator]: Done with epoch\n",
      "\n",
      "[INFO] [LambdaCheckpointHook]: Saved model to logs/2020-01-05T15-21-19_tflow/train/checkpoints/model-120.ckpt\n",
      "[INFO] [LambdaCheckpointHook]: Saved model to logs/2020-01-05T15-21-19_tflow/train/checkpoints/model-120.ckpt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Trainer.iterate(make_batches(Moon, batch_size=64, shuffle=True))\n",
    "\n",
    "del P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
